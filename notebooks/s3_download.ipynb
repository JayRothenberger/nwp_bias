{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s3_download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to download the forecast systems "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful resources \n",
    "- Lauriana Gaudet created original code : https://github.com/lgaudet/AI2ES-notebooks/blob/master/s3_download.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages not in this env in the current Jupyter kernel\n",
    "# can comment out or delete when they are installed in environment\n",
    "import sys\n",
    "#!{sys.executable} -m pip install s3fs\n",
    "#!{sys.executable} -m pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import s3fs\n",
    "import argparse\n",
    "from datetime import datetime, date\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import time\n",
    "import glob\n",
    "\n",
    "from boto3 import client\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_s3_file(bucket, ingest_path, output_path):\n",
    "    fs = s3fs.S3FileSystem(anon=True, asynchronous=False)\n",
    "        \n",
    "    if fs.exists(f'{bucket}/{ingest_path}'):\n",
    "        # Download file, will throw FileNotFoundError if non existent\n",
    "        fs.download(\n",
    "            f'{bucket}/{ingest_path}', output_path\n",
    "        )\n",
    "        print(f'✅ downloading {ingest_path} & saving to {output_path}')\n",
    "    else:\n",
    "        print(f'‼️ file not found {ingest_path}')\n",
    "\n",
    "def list_s3_files(bucket, model, date, init_time, data_type):\n",
    "    conn = client('s3', config=Config(signature_version=UNSIGNED))\n",
    "    \n",
    "    if model == 'nam':\n",
    "        prefix = f'{model}.{date}/'\n",
    "    elif model == 'gfs':\n",
    "        prefix = f'{model}.{date}/{init_time}/atmos/'\n",
    "    elif model == 'hrrr':\n",
    "        prefix = f'{model}.{date}/conus/'\n",
    "    \n",
    "    response = conn.list_objects_v2(Bucket=bucket, Prefix=f'{prefix}{model}.t{init_time}z.{data_type}')\n",
    "    files = response.get('Contents')\n",
    "    if files:\n",
    "        all_files = [file.get('Key') for file in files]\n",
    "        existing_files_for_download = [file for file in all_files if f't{init_time}z.{data_type}' in file and not file.endswith('idx') and not file.endswith('anl')]\n",
    "        existing_files_for_download.sort()\n",
    "        return existing_files_for_download\n",
    "    else:\n",
    "        return []   \n",
    "\n",
    "def get_avail_files(s3_bucket, model, year, month, day, init_time, data_type, split_loc, fh_loc, fxx_max, zfill,\n",
    "                   download_dir, fname_out, fname_end, full_filelist_len):\n",
    "    ii=0\n",
    "    len_files_for_download = [0]\n",
    "    while True:\n",
    "        files_for_download = list_s3_files(s3_bucket, model, f'{year}{month}{day}', init_time, data_type)    \n",
    "        files_for_download = [file for file in files_for_download if int(file.split('.')[split_loc][fh_loc:]) <= fxx_max]\n",
    "        print(files_for_download)\n",
    "        len_files_for_download.append(len(files_for_download))\n",
    "        for file in files_for_download:\n",
    "            fxx = file.split('.')[split_loc][fh_loc:]\n",
    "            if not os.path.isdir(download_dir):\n",
    "                print('making directory: ', download_dir)\n",
    "                Path(download_dir).mkdir(parents=True, exist_ok=True)\n",
    "            # check to see if output_path is a directory. if not, create directory\n",
    "            output_path = f'{download_dir}{fname_out}{str(fxx).zfill(zfill)}{fname_end}'\n",
    "            if not os.path.exists(output_path):\n",
    "                # if the file already exists, do not redownload\n",
    "                download_s3_file(s3_bucket, file, output_path)\n",
    "                # call the rest of the pipeline here, run_pipeline\n",
    "                # running cleaning through the pipeline could be the \"sleep\" period\n",
    "                print('FXX IS: ', fxx)\n",
    "            else:\n",
    "                print(f'file has already been downloaded: {output_path}')\n",
    "                \n",
    "        # STOP WHILE LOOP IF ALL DESIRED FILES HAVE BEEN DOWNLOADED ON OUR SIDE\n",
    "        if os.path.isdir(download_dir):\n",
    "            files_downloaded = glob.glob(f'{download_dir}{fname_out}*{fname_end}')\n",
    "            num_files_downloaded = len(files_downloaded)\n",
    "            print(num_files_downloaded)\n",
    "            if num_files_downloaded >= full_filelist_len:\n",
    "                print('exiting from while loop')\n",
    "                break\n",
    "                \n",
    "        #if no additional files are available compared to last try but the full_filelist_len has not been reached yet...\n",
    "        if len_files_for_download[-1]==len_files_for_download[-2]: \n",
    "            ii+=1\n",
    "            print('same number of available files as last try. ii=',ii)\n",
    "            if ii>10: #stop waiting for additional file if we have tried 10 separate times\n",
    "                print('waited too long for new file, exiting while loop')\n",
    "                break\n",
    "\n",
    "        # try again in 90 seconds\n",
    "        print('sleep: ', datetime.now())\n",
    "        time.sleep(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model, data_type, init_date, init_time):\n",
    "    month = str(init_date.month).zfill(2)\n",
    "    year = init_date.year\n",
    "    day = str(init_date.day).zfill(2)\n",
    " \n",
    "    download_dir = f'/home/lgaudet/model-data/{model.upper()}/{year}/{month}/'\n",
    "    \n",
    "    if model == 'nam':\n",
    "        s3_bucket = f'noaa-{model}-pds'\n",
    "    else:\n",
    "        s3_bucket = f'noaa-{model}-bdp-pds'\n",
    "    \n",
    "    if model == 'nam':\n",
    "        fxx_max = 84\n",
    "        split_loc, fh_loc = -3, -2\n",
    "        fname_out = f'nam_218_{year}{month}{day}_{init_time}00_'\n",
    "        fname_end = '.grb2'\n",
    "        zfill = 3\n",
    "        full_filelist_len = len(np.arange(0,37,1).tolist() + np.arange(39,85,3).tolist())\n",
    "    elif model == 'gfs':\n",
    "        fxx_max = 96\n",
    "        split_loc, fh_loc = -1, 1\n",
    "        fname_out = f'gfs_4_{year}{month}{day}_{init_time}00_'\n",
    "        fname_end = '.grb2'\n",
    "        zfill = 3\n",
    "        full_filelist_len = len(np.arange(0, 99, 3))\n",
    "    elif model == 'hrrr':\n",
    "        fxx_max = 18\n",
    "        split_loc, fh_loc = -2, -2\n",
    "        fname_out = f'{year}{month}{day}_hrrr.t{init_time}z.wrfsfcf'\n",
    "        fname_end = '.grib2'\n",
    "        zfill = 2\n",
    "        full_filelist_len = len(range(0, 19))        \n",
    "    \n",
    "    get_avail_files(s3_bucket, model, year, month, day, init_time, data_type, split_loc, fh_loc, fxx_max, zfill,\n",
    "                   download_dir, fname_out, fname_end, full_filelist_len)\n",
    "    \n",
    "    print(f'full download for {init_time}z initialization of the {model.upper()} complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type_dict = {'gfs':'pgrb2.0p50', 'nam':'awphys', 'hrrr':'wrfsfc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get todays date \n",
    "today = date.today()\n",
    "# year\n",
    "year = today.strftime(\"%Y\")\n",
    "# month\n",
    "month = today.strftime(\"%m\")\n",
    "# day\n",
    "day = today.strftime(\"%d\")\n",
    "\n",
    "# start run from this initialization point\n",
    "init_time = '00'\n",
    "init_date = datetime(int(year), int(month), int(day))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f000', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f003', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f006', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f009', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f012', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f015', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f018', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f021', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f024', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f027', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f030', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f033', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f036', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f039', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f042', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f045', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f048', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f051', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f054', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f057', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f060', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f063', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f066', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f069', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f072', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f075', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f078', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f081', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f084', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f087', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f090', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f093', 'gfs.20221020/00/atmos/gfs.t00z.pgrb2.0p50.f096']\n",
      "making directory:  /home/lgaudet/model-data/GFS/2022/10/\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/home/lgaudet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib64/python3.9/pathlib.py:1323\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1323\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor\u001b[39m.\u001b[39;49mmkdir(\u001b[39mself\u001b[39;49m, mode)\n\u001b[1;32m   1324\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/lgaudet/model-data/GFS/2022/10'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib64/python3.9/pathlib.py:1323\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1323\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor\u001b[39m.\u001b[39;49mmkdir(\u001b[39mself\u001b[39;49m, mode)\n\u001b[1;32m   1324\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/lgaudet/model-data/GFS/2022'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib64/python3.9/pathlib.py:1323\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1323\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor\u001b[39m.\u001b[39;49mmkdir(\u001b[39mself\u001b[39;49m, mode)\n\u001b[1;32m   1324\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/lgaudet/model-data/GFS'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib64/python3.9/pathlib.py:1323\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1323\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor\u001b[39m.\u001b[39;49mmkdir(\u001b[39mself\u001b[39;49m, mode)\n\u001b[1;32m   1324\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/lgaudet/model-data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m main(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgfs\u001b[39m\u001b[38;5;124m'\u001b[39m, data_type_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgfs\u001b[39m\u001b[38;5;124m'\u001b[39m), init_date, init_time)\n",
      "Cell \u001b[0;32mIn [37], line 35\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(model, data_type, init_date, init_time)\u001b[0m\n\u001b[1;32m     32\u001b[0m     zfill \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     33\u001b[0m     full_filelist_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m19\u001b[39m))        \n\u001b[0;32m---> 35\u001b[0m \u001b[43mget_avail_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms3_bucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_loc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfh_loc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfxx_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzfill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m               \u001b[49m\u001b[43mdownload_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_filelist_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull download for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minit_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mz initialization of the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m complete!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn [36], line 46\u001b[0m, in \u001b[0;36mget_avail_files\u001b[0;34m(s3_bucket, model, year, month, day, init_time, data_type, split_loc, fh_loc, fxx_max, zfill, download_dir, fname_out, fname_end, full_filelist_len)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(download_dir):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaking directory: \u001b[39m\u001b[38;5;124m'\u001b[39m, download_dir)\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# check to see if output_path is a directory. if not, create directory\u001b[39;00m\n\u001b[1;32m     48\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdownload_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfname_out\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(fxx)\u001b[38;5;241m.\u001b[39mzfill(zfill)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfname_end\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/usr/lib64/python3.9/pathlib.py:1327\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parents \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparent \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m:\n\u001b[1;32m   1326\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m-> 1327\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49mmkdir(parents\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, exist_ok\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1328\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmkdir(mode, parents\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, exist_ok\u001b[39m=\u001b[39mexist_ok)\n\u001b[1;32m   1329\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m   1330\u001b[0m     \u001b[39m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib64/python3.9/pathlib.py:1327\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parents \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparent \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m:\n\u001b[1;32m   1326\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m-> 1327\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49mmkdir(parents\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, exist_ok\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1328\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmkdir(mode, parents\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, exist_ok\u001b[39m=\u001b[39mexist_ok)\n\u001b[1;32m   1329\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m   1330\u001b[0m     \u001b[39m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Path.mkdir at line 1327 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m/usr/lib64/python3.9/pathlib.py:1327\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parents \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparent \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m:\n\u001b[1;32m   1326\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m-> 1327\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49mmkdir(parents\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, exist_ok\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1328\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmkdir(mode, parents\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, exist_ok\u001b[39m=\u001b[39mexist_ok)\n\u001b[1;32m   1329\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m   1330\u001b[0m     \u001b[39m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib64/python3.9/pathlib.py:1323\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m \u001b[39mCreate a new directory at this given path.\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1323\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor\u001b[39m.\u001b[39;49mmkdir(\u001b[39mself\u001b[39;49m, mode)\n\u001b[1;32m   1324\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m   1325\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parents \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparent \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m:\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/home/lgaudet'"
     ]
    }
   ],
   "source": [
    "main('gfs', data_type_dict.get('gfs'), init_date, init_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('nam', data_type_dict.get('nam'), init_date, init_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HRRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('hrrr', data_type_dict.get('hrrr'), init_date, init_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
