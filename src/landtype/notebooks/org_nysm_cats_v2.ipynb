{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "# instead of creating a package using setup.py or building from a docker/singularity file,\n",
    "# import the sister directory of src code to be called on in notebook.\n",
    "# This keeps the notebook free from code to only hold visualizations and is easier to test\n",
    "# It also helps keep the state of variables clean such that cells aren't run out of order with a mysterious state\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# import sklearn.cluster.hierarchical as hclust\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from src import most_recent_mesonet_data\n",
    "from src import most_recent_mesonet_time\n",
    "from src import landtype_describe\n",
    "from src import get_represents\n",
    "\n",
    "from src.plotting_scripts import landtype\n",
    "from src.plotting_scripts import stackplot\n",
    "from src.plotting_scripts import rose_plot\n",
    "from src.plotting_scripts import stacks\n",
    "from src.plotting_scripts import stat_scatterplot\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import cartopy.crs as crs\n",
    "import cartopy.feature as cfeature\n",
    "from scipy.stats import skew\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df(df):\n",
    "    \"\"\"Format a DataFrame with counts of values into a DataFrame with individual values\n",
    "\n",
    "    Args:\n",
    "    - df: A pandas DataFrame with columns \"COUNT\" and \"VALUE\"\n",
    "\n",
    "    Returns:\n",
    "    - A new pandas DataFrame with a single column \"VALUE\" containing individual values\n",
    "\n",
    "    Example:\n",
    "    input DataFrame:\n",
    "\n",
    "    | COUNT | VALUE |\n",
    "    |-------|-------|\n",
    "    |   2   |  10   |\n",
    "    |   3   |  20   |\n",
    "    |   1   |  30   |\n",
    "\n",
    "    output DataFrame:\n",
    "\n",
    "    | VALUE |\n",
    "    |-------|\n",
    "    |  10   |\n",
    "    |  10   |\n",
    "    |  20   |\n",
    "    |  20   |\n",
    "    |  20   |\n",
    "    |  30   |\n",
    "    \"\"\"\n",
    "\n",
    "    new_df = pd.DataFrame()\n",
    "    value_list = []\n",
    "\n",
    "    # iterate over the rows of the input DataFrame\n",
    "    for x, _ in df.iterrows():\n",
    "        # extract the count and value from each row\n",
    "        count = int(df.iloc[x][\"Count\"])\n",
    "        value = df.iloc[x][\"Value\"]\n",
    "\n",
    "        # repeat the value the specified number of times\n",
    "        for n in np.arange(count):\n",
    "            val = value\n",
    "            value_list.append(val)\n",
    "\n",
    "    # create a new DataFrame with the individual values\n",
    "    new_df[\"Value\"] = value_list\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(clim_div_int, climate_division):\n",
    "    # read csvs\n",
    "    nysm_cats_df = pd.read_csv(\"/home/aevans/nwp_bias/src/landtype/data/nysm.csv\")\n",
    "    # LULC\n",
    "    lulc_df = pd.read_csv(\"/home/aevans/nwp_bias/src/correlation/data/nlcd_nam.csv\")\n",
    "    # elevation\n",
    "    elev_df = pd.read_csv(\"/home/aevans/nwp_bias/src/correlation/data/elev_nam.csv\")\n",
    "    # aspect/slope\n",
    "    asp_slop_df = pd.read_csv(\n",
    "        \"/home/aevans/nwp_bias/src/correlation/data/aspect_nam.csv\"\n",
    "    )\n",
    "\n",
    "    # get and format csvs from clim region\n",
    "    # get\n",
    "    nlcd_df = pd.read_csv(\n",
    "        f\"/home/aevans/nwp_bias/src/landtype/data/org_cats_geoinfo/{climate_division}_lulc.csv\"\n",
    "    )\n",
    "    nlcd_df = nlcd_df.drop(columns=[\"OID_\", \"Red\", \"Blue\", \"Green\", \"Opacity\"])\n",
    "    aspect_df = pd.read_csv(\n",
    "        f\"/home/aevans/nwp_bias/src/landtype/data/org_cats_geoinfo/{climate_division}_asp_slope.csv\"\n",
    "    )\n",
    "    elevation_df = pd.read_csv(\n",
    "        f\"/home/aevans/nwp_bias/src/landtype/data/org_cats_geoinfo/{climate_division}_elevs.csv\"\n",
    "    )\n",
    "    elevation_df = format_df(elevation_df)\n",
    "    # format\n",
    "    df_y = aspect_df.assign(\n",
    "        Percentage=lambda x: (x[\"Count\"] / sum(aspect_df[\"Count\"]) * 100)\n",
    "    )\n",
    "    df_x = nlcd_df.assign(\n",
    "        Percentage=lambda x: (x[\"Count\"] / sum(nlcd_df[\"Count\"]) * 100)\n",
    "    )\n",
    "    mean = elevation_df[\"Value\"].mean()\n",
    "    my_skew = skew(elevation_df[\"Value\"])\n",
    "\n",
    "    # concat and get first clim division\n",
    "    clim1_df = pd.concat([nysm_cats_df, lulc_df, elev_df, asp_slop_df], axis=1)\n",
    "    clim1_df = clim1_df[clim1_df[\"climate_division\"] == clim_div_int]\n",
    "    lons = clim1_df[\"lon [degrees]\"].tolist()\n",
    "    lats = clim1_df[\"lat [degrees]\"].tolist()\n",
    "    elevs = clim1_df[\"elev\"].tolist()\n",
    "    sites = clim1_df[\"stid\"].tolist()\n",
    "\n",
    "    # LULC\n",
    "    print(\"LULC\")\n",
    "    stack_df = lulc_df[lulc_df[\"station\"].isin(clim1_df[\"stid\"])]\n",
    "    stack_df = get_represents.get_represent(stack_df, df_x)\n",
    "\n",
    "    # Aspect/Slope\n",
    "    print(\"Aspect/Slope\")\n",
    "    stack_df1 = asp_slop_df[asp_slop_df[\"station\"].isin(clim1_df[\"stid\"])]\n",
    "    stack_df1 = get_represents.get_represent(stack_df1, df_y)\n",
    "\n",
    "    # Elevation\n",
    "    print(\"Elevation\")\n",
    "    stack_df2 = elev_df[elev_df[\"station\"].isin(clim1_df[\"stid\"])]\n",
    "    stack_df2 = stack_df2.drop(\n",
    "        columns=[\"Unnamed: 0\", \"station\", \"med_dist\", \"lat\", \"lon\", \"variance\", \"std\"]\n",
    "    )\n",
    "    stack_df2[\"elev\"] = (mean - stack_df2[\"elev\"]) / stack_df2[\"elev\"].std()\n",
    "    stack_df2[\"sums\"] = stack_df2.sum(axis=1)\n",
    "    stack_df2[\"sums\"] = (stack_df2[\"sums\"]) / stack_df2[\"sums\"].std()\n",
    "    stack_df2[\"station\"] = sites\n",
    "\n",
    "    # final eval\n",
    "    df = pd.DataFrame()\n",
    "    df[\"sums\"] = stack_df[\"sums\"] + stack_df1[\"sums\"] + stack_df2[\"sums\"]\n",
    "    df[\"sums\"] = df[\"sums\"] / df[\"sums\"].std()\n",
    "    df[\"station\"] = sites\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LULC\n",
      "Aspect/Slope\n",
      "Elevation\n"
     ]
    }
   ],
   "source": [
    "df = main(1, \"west_plat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sums</th>\n",
       "      <th>station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.339027</td>\n",
       "      <td>ADDI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.223960</td>\n",
       "      <td>BELM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.044861</td>\n",
       "      <td>COHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.303897</td>\n",
       "      <td>DELE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2.501506</td>\n",
       "      <td>ELMI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-0.399560</td>\n",
       "      <td>GROV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-0.781571</td>\n",
       "      <td>HART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1.138078</td>\n",
       "      <td>OLEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1.075550</td>\n",
       "      <td>RAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sums station\n",
       "0   0.339027    ADDI\n",
       "6   1.223960    BELM\n",
       "28 -0.044861    COHO\n",
       "34  0.303897    DELE\n",
       "43  2.501506    ELMI\n",
       "51 -0.399560    GROV\n",
       "55 -0.781571    HART\n",
       "73  1.138078    OLEA\n",
       "85  1.075550    RAND"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44818f36aeaf89db1a1d21a2bee6031a28b4e41595a65903b38b9b0c4417365f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
