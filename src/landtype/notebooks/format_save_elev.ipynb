{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "# instead of creating a package using setup.py or building from a docker/singularity file,\n",
    "# import the sister directory of src code to be called on in notebook.\n",
    "# This keeps the notebook free from code to only hold visualizations and is easier to test\n",
    "# It also helps keep the state of variables clean such that cells aren't run out of order with a mysterious state\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "import statistics\n",
    "import cartopy.crs as crs\n",
    "import cartopy.feature as cfeature\n",
    "import xarray as xr\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df(df):\n",
    "    new_df = pd.DataFrame()\n",
    "    value_list = []\n",
    "    for x, _ in df.iterrows():\n",
    "        count = int(df.iloc[x][\"COUNT\"])\n",
    "        value = df.iloc[x][\"VALUE\"]\n",
    "        for n in np.arange(count):\n",
    "            val = value\n",
    "            value_list.append(val)\n",
    "    new_df[\"VALUE\"] = value_list\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def stat_anal(directory, state_df, station_list, lonlist, latlist):\n",
    "    final_df = pd.DataFrame()\n",
    "    std_list = []\n",
    "    variance_list = []\n",
    "    skew_list = []\n",
    "    distance_list = []\n",
    "    stations = []\n",
    "    elevs = []\n",
    "    x=0\n",
    "    for i in np.arange(1,127):\n",
    "        # read in csv\n",
    "        df2 = pd.DataFrame()\n",
    "        elev_df = pd.read_csv(\n",
    "            f\"/home/aevans/nwp_bias/src/landtype/elevation/data/NY/elev/gfs/aspect_csv_{i}.csv\"\n",
    "        )\n",
    "        dfv1 = format_df(elev_df)\n",
    "        std = statistics.stdev(dfv1[\"VALUE\"])\n",
    "        variance = statistics.pvariance(dfv1[\"VALUE\"])\n",
    "        my_skew = skew(dfv1[\"VALUE\"])\n",
    "        elevation = state_df[\"elev\"].iloc[x]\n",
    "        station = station_list[x]\n",
    "        split_diff = dfv1[\"VALUE\"] - state_df[\"elev\"].iloc[x]\n",
    "        diff_list = split_diff.to_list()\n",
    "        df2[\"diff_elev\"] = diff_list\n",
    "        describe = df2[\"diff_elev\"].describe()\n",
    "        fifty = describe[5]\n",
    "        distance = state_df[\"elev\"].iloc[x] - fifty\n",
    "        # add data\n",
    "        stations.append(station)\n",
    "        elevs.append(elevation)\n",
    "        distance_list.append(distance)\n",
    "        skew_list.append(my_skew)\n",
    "        variance_list.append(variance)\n",
    "        std_list.append(std)\n",
    "        x+=1\n",
    "\n",
    "    final_df[\"station\"] = stations\n",
    "    final_df[\"elev\"] = elevs\n",
    "    final_df[\"std\"] = std_list\n",
    "    final_df[\"variance\"] = variance_list\n",
    "    final_df[\"skew\"] = skew_list\n",
    "    final_df[\"med_dist\"] = distance_list\n",
    "    final_df[\"lon\"] = lonlist\n",
    "    final_df[\"lat\"] = latlist\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_time_mesonet_df(mesonet_data_path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This will return a dataframe that contains data from the mesonet sites\n",
    "\n",
    "    Args:\n",
    "        Mesonet Data Path (f string)\n",
    "\n",
    "    Returns:\n",
    "        df (pd.DataFrame): Mesonet Data Frame\n",
    "    \"\"\"\n",
    "\n",
    "    # most recent year\n",
    "    dir_Year = os.listdir(f\"{mesonet_data_path}\")\n",
    "    sort_dir_Year = sorted(dir_Year)\n",
    "    data_point_Year = sort_dir_Year[-1]\n",
    "\n",
    "    # find most recent month\n",
    "    dir_Month = os.listdir(f\"{mesonet_data_path}/{data_point_Year}\")\n",
    "    sort_dir_Month = sorted(dir_Month)\n",
    "    data_point_Month = sort_dir_Month[-1]\n",
    "\n",
    "    # this is your directory for most recent year and month\n",
    "    most_recent = os.listdir(\n",
    "        f\"{mesonet_data_path}/{data_point_Year}/{data_point_Month}\"\n",
    "    )\n",
    "\n",
    "    # most recent datapoint\n",
    "    sort_most_recent = sorted(most_recent)\n",
    "    data_point = sort_most_recent[-1]\n",
    "\n",
    "    # this will return the year of the most recent data point\n",
    "    new_year = data_point[0:4]\n",
    "\n",
    "    # this will return the month of the most recent datapoint\n",
    "    new_month = data_point[4:6]\n",
    "\n",
    "    # this will return the day of the most recent datapoint\n",
    "    new_day = data_point[6:8]\n",
    "\n",
    "    # create Mesonet DataFrame\n",
    "\n",
    "    # year\n",
    "    year = new_year\n",
    "\n",
    "    # month\n",
    "    month = new_month\n",
    "\n",
    "    # day\n",
    "    day = new_day\n",
    "\n",
    "    # file path\n",
    "    file = year + month + day + \".nc\"\n",
    "\n",
    "    mesonet_df = (\n",
    "        xr.open_dataset(f\"{mesonet_data_path}/{year}/{month}/{file}\")\n",
    "        .to_dataframe()\n",
    "        .reset_index()\n",
    "    )\n",
    "    return mesonet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_recent_time(df: pd.DataFrame, mesonet_data_path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This will return a dataframe that contains only the timestamps with filled data from the mesonet sites\n",
    "\n",
    "    Args:\n",
    "    Mesonet Data Path (f string)\n",
    "\n",
    "    Returns:\n",
    "    df (pd.DataFrame): Mesonet Data Frame\n",
    "    \"\"\"\n",
    "\n",
    "    # most recent year\n",
    "    dir_Year = os.listdir(f\"{mesonet_data_path}\")\n",
    "    sort_dir_Year = sorted(dir_Year)\n",
    "    data_point_Year = sort_dir_Year[-1]\n",
    "\n",
    "    # find most recent month\n",
    "    dir_Month = os.listdir(f\"{mesonet_data_path}/{data_point_Year}\")\n",
    "    sort_dir_Month = sorted(dir_Month)\n",
    "    data_point_Month = sort_dir_Month[-1]\n",
    "\n",
    "    # this is your directory for most recent year and month\n",
    "    most_recent = os.listdir(\n",
    "        f\"{mesonet_data_path}/{data_point_Year}/{data_point_Month}\"\n",
    "    )\n",
    "\n",
    "    # most recent datapoint\n",
    "    sort_most_recent = sorted(most_recent)\n",
    "    data_point = sort_most_recent[-1]\n",
    "\n",
    "    # this will return the year of the most recent data point\n",
    "    new_year = data_point[0:4]\n",
    "\n",
    "    # this will return the month of the most recent datapoint\n",
    "    new_month = data_point[4:6]\n",
    "\n",
    "    # this will return the day of the most recent datapoint\n",
    "    new_day = data_point[6:8]\n",
    "\n",
    "    # create Mesonet DataFrame\n",
    "\n",
    "    # year\n",
    "    year = new_year\n",
    "\n",
    "    # month\n",
    "    month = new_month\n",
    "\n",
    "    # day\n",
    "    day = new_day\n",
    "\n",
    "    current_time_df = df.dropna(subset=[\"tair\"])\n",
    "\n",
    "    last_value = current_time_df[\"time_5M\"].iat[-1]\n",
    "    hour = last_value.hour\n",
    "    minute = last_value.minute\n",
    "    second = last_value.second\n",
    "\n",
    "    string_hour = str(hour)\n",
    "    string_minute = str(minute)\n",
    "    string_sec = str(second)\n",
    "\n",
    "    # time\n",
    "    time = string_hour + \":\" + string_minute + \":\" + string_sec\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # creating a new dataframe that is centered on the location in the dataframe\n",
    "    mesonet_single_datetime_df = df.loc[df[\"time_5M\"] == f\"{year}-{month}-{day} {time}\"]\n",
    "    return mesonet_single_datetime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return the most recent data avail on mesonet\n",
    "# this is my file path\n",
    "ny_df = pd.read_csv(\"/home/aevans/nwp_bias/src/landtype/notebooks/nysm_coords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return the most recent data avail on mesonet\n",
    "# this is my file path\n",
    "ny_mesonet_data_path = \"/home/aevans/nysm/archive/nysm/netcdf/proc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_df1 = current_time_mesonet_df(ny_mesonet_data_path)\n",
    "nysm_df = most_recent_time(nysm_df1, ny_mesonet_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_df['elev'] = nysm_df['elev'].to_list()\n",
    "ny_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.listdir(f\"/home/aevans/nwp_bias/src/landtype/elevation/data/NY/elev/nam\")\n",
    "sorted_direct = sorted(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to data\n",
    "path_ny = f\"/home/aevans/nwp_bias/src/landtype/elevation/data/CSVs_elevation_ny_gfs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_list_ny = ny_df[\"station\"].to_list()\n",
    "ny_df_lons = ny_df[\"longitude\"].to_list()\n",
    "ny_df_lats = ny_df[\"latitude\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "for i in range(1, 127):\n",
    "    df = pd.read_csv(f\"/home/aevans/nwp_bias/src/landtype/elevation/data/CSVs_slope_ny_gfs/aspect_csv_{i}.csv\")\n",
    "    df.to_csv(\n",
    "        f\"/home/aevans/nwp_bias/src/landtype/elevation/data/NY/elev/gfs/{station_list_ny[x]}_elev.csv\"\n",
    "    )\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_df = stat_anal(\n",
    "    sorted_direct, ny_df, station_list_ny, ny_df_lons, ny_df_lats\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_df.to_csv(\"/home/aevans/nwp_bias/src/correlation/data/elev_gfs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44818f36aeaf89db1a1d21a2bee6031a28b4e41595a65903b38b9b0c4417365f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
