{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "# instead of creating a package using setup.py or building from a docker/singularity file,\n",
    "# import the sister directory of src code to be called on in notebook.\n",
    "# This keeps the notebook free from code to only hold visualizations and is easier to test\n",
    "# It also helps keep the state of variables clean such that cells aren't run out of order with a mysterious state\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "import statistics\n",
    "import cartopy.crs as crs\n",
    "import cartopy.feature as cfeature\n",
    "import xarray as xr\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df(df):\n",
    "    \"\"\"Format a DataFrame with counts of values into a DataFrame with individual values\n",
    "    \n",
    "    Args:\n",
    "    - df: A pandas DataFrame with columns \"COUNT\" and \"VALUE\"\n",
    "    \n",
    "    Returns:\n",
    "    - A new pandas DataFrame with a single column \"VALUE\" containing individual values\n",
    "    \n",
    "    Example:\n",
    "    input DataFrame:\n",
    "    \n",
    "    | COUNT | VALUE |\n",
    "    |-------|-------|\n",
    "    |   2   |  10   |\n",
    "    |   3   |  20   |\n",
    "    |   1   |  30   |\n",
    "    \n",
    "    output DataFrame:\n",
    "    \n",
    "    | VALUE |\n",
    "    |-------|\n",
    "    |  10   |\n",
    "    |  10   |\n",
    "    |  20   |\n",
    "    |  20   |\n",
    "    |  20   |\n",
    "    |  30   |\n",
    "    \"\"\"\n",
    "    \n",
    "    new_df = pd.DataFrame()\n",
    "    value_list = []\n",
    "    \n",
    "    # iterate over the rows of the input DataFrame\n",
    "    for x, _ in df.iterrows():\n",
    "        \n",
    "        # extract the count and value from each row\n",
    "        count = int(df.iloc[x][\"COUNT\"])\n",
    "        value = df.iloc[x][\"VALUE\"]\n",
    "        \n",
    "        # repeat the value the specified number of times\n",
    "        for n in np.arange(count):\n",
    "            val = value\n",
    "            value_list.append(val)\n",
    "    \n",
    "    # create a new DataFrame with the individual values\n",
    "    new_df[\"VALUE\"] = value_list\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "\n",
    "\n",
    "def stat_anal(directory, state_df, station_list, lonlist, latlist):\n",
    "    \"\"\"\n",
    "    Performs statistical analysis on a set of elevation data for a given state.\n",
    "\n",
    "    Args:\n",
    "    directory (str): File directory where the elevation data is stored.\n",
    "    state_df (pandas DataFrame): DataFrame containing the elevation data for each station in the state.\n",
    "    station_list (list): List of station IDs.\n",
    "    lonlist (list): List of longitude coordinates for each station.\n",
    "    latlist (list): List of latitude coordinates for each station.\n",
    "\n",
    "    Returns:\n",
    "    final_df (pandas DataFrame): DataFrame containing the results of the statistical analysis.\n",
    "    Columns include: \"station\", \"elev\", \"std\", \"variance\", \"skew\", \"med_dist\", \"lon\", and \"lat\".\n",
    "    \"\"\"\n",
    "\n",
    "    final_df = pd.DataFrame()\n",
    "    std_list = []\n",
    "    variance_list = []\n",
    "    skew_list = []\n",
    "    distance_list = []\n",
    "    stations = []\n",
    "    elevs = []\n",
    "    x = 0\n",
    "    for i in np.arange(1, 127):\n",
    "        # read in csv\n",
    "        df2 = pd.DataFrame()\n",
    "        elev_df = pd.read_csv(\n",
    "            f\"{directory}/gfs/aspect_csv_{i}.csv\"\n",
    "        )\n",
    "        dfv1 = format_df(elev_df)  # apply format_df to the elevation data\n",
    "        std = statistics.stdev(dfv1[\"VALUE\"])  # calculate the standard deviation\n",
    "        variance = statistics.pvariance(dfv1[\"VALUE\"])  # calculate the variance\n",
    "        my_skew = skew(dfv1[\"VALUE\"])  # calculate the skewness\n",
    "        elevation = state_df[\"elev\"].iloc[x]  # get the elevation for the current station\n",
    "        station = station_list[x]  # get the station ID for the current station\n",
    "        split_diff = dfv1[\"VALUE\"] - state_df[\"elev\"].iloc[x]  # calculate the difference between elevation and state_df\n",
    "        diff_list = split_diff.to_list()  # convert the difference to a list\n",
    "        df2[\"diff_elev\"] = diff_list  # add the difference to the DataFrame\n",
    "        describe = df2[\"diff_elev\"].describe()  # calculate the descriptive statistics for the difference\n",
    "        fifty = describe[5]  # get the median of the difference\n",
    "        distance = state_df[\"elev\"].iloc[x] - fifty  # calculate the median distance\n",
    "        # add data to lists\n",
    "        stations.append(station)\n",
    "        elevs.append(elevation)\n",
    "        distance_list.append(distance)\n",
    "        skew_list.append(my_skew)\n",
    "        variance_list.append(variance)\n",
    "        std_list.append(std)\n",
    "        x += 1\n",
    "\n",
    "    final_df[\"station\"] = stations\n",
    "    final_df[\"elev\"] = elevs\n",
    "    final_df[\"std\"] = std_list\n",
    "    final_df[\"variance\"] = variance_list\n",
    "    final_df[\"skew\"] = skew_list\n",
    "    final_df[\"med_dist\"] = distance_list\n",
    "    final_df[\"lon\"] = lonlist\n",
    "    final_df[\"lat\"] = latlist\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_time_mesonet_df(mesonet_data_path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This will return a dataframe that contains data from the mesonet sites\n",
    "\n",
    "    Args:\n",
    "        Mesonet Data Path (f string)\n",
    "\n",
    "    Returns:\n",
    "        df (pd.DataFrame): Mesonet Data Frame\n",
    "    \"\"\"\n",
    "\n",
    "    # most recent year\n",
    "    dir_Year = os.listdir(f\"{mesonet_data_path}\")\n",
    "    sort_dir_Year = sorted(dir_Year)\n",
    "    data_point_Year = sort_dir_Year[-1]\n",
    "\n",
    "    # find most recent month\n",
    "    dir_Month = os.listdir(f\"{mesonet_data_path}/{data_point_Year}\")\n",
    "    sort_dir_Month = sorted(dir_Month)\n",
    "    data_point_Month = sort_dir_Month[-1]\n",
    "\n",
    "    # this is your directory for most recent year and month\n",
    "    most_recent = os.listdir(\n",
    "        f\"{mesonet_data_path}/{data_point_Year}/{data_point_Month}\"\n",
    "    )\n",
    "\n",
    "    # most recent datapoint\n",
    "    sort_most_recent = sorted(most_recent)\n",
    "    data_point = sort_most_recent[-1]\n",
    "\n",
    "    # this will return the year of the most recent data point\n",
    "    new_year = data_point[0:4]\n",
    "\n",
    "    # this will return the month of the most recent datapoint\n",
    "    new_month = data_point[4:6]\n",
    "\n",
    "    # this will return the day of the most recent datapoint\n",
    "    new_day = data_point[6:8]\n",
    "\n",
    "    # create Mesonet DataFrame\n",
    "\n",
    "    # year\n",
    "    year = new_year\n",
    "\n",
    "    # month\n",
    "    month = new_month\n",
    "\n",
    "    # day\n",
    "    day = new_day\n",
    "\n",
    "    # file path\n",
    "    file = year + month + day + \".nc\"\n",
    "\n",
    "    mesonet_df = (\n",
    "        xr.open_dataset(f\"{mesonet_data_path}/{year}/{month}/{file}\")\n",
    "        .to_dataframe()\n",
    "        .reset_index()\n",
    "    )\n",
    "    return mesonet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_recent_time(df: pd.DataFrame, mesonet_data_path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This will return a dataframe that contains only the timestamps with filled data from the mesonet sites\n",
    "\n",
    "    Args:\n",
    "    Mesonet Data Path (f string)\n",
    "\n",
    "    Returns:\n",
    "    df (pd.DataFrame): Mesonet Data Frame\n",
    "    \"\"\"\n",
    "\n",
    "    # most recent year\n",
    "    dir_Year = os.listdir(f\"{mesonet_data_path}\")\n",
    "    sort_dir_Year = sorted(dir_Year)\n",
    "    data_point_Year = sort_dir_Year[-1]\n",
    "\n",
    "    # find most recent month\n",
    "    dir_Month = os.listdir(f\"{mesonet_data_path}/{data_point_Year}\")\n",
    "    sort_dir_Month = sorted(dir_Month)\n",
    "    data_point_Month = sort_dir_Month[-1]\n",
    "\n",
    "    # this is your directory for most recent year and month\n",
    "    most_recent = os.listdir(\n",
    "        f\"{mesonet_data_path}/{data_point_Year}/{data_point_Month}\"\n",
    "    )\n",
    "\n",
    "    # most recent datapoint\n",
    "    sort_most_recent = sorted(most_recent)\n",
    "    data_point = sort_most_recent[-1]\n",
    "\n",
    "    # this will return the year of the most recent data point\n",
    "    new_year = data_point[0:4]\n",
    "\n",
    "    # this will return the month of the most recent datapoint\n",
    "    new_month = data_point[4:6]\n",
    "\n",
    "    # this will return the day of the most recent datapoint\n",
    "    new_day = data_point[6:8]\n",
    "\n",
    "    # create Mesonet DataFrame\n",
    "\n",
    "    # year\n",
    "    year = new_year\n",
    "\n",
    "    # month\n",
    "    month = new_month\n",
    "\n",
    "    # day\n",
    "    day = new_day\n",
    "\n",
    "    current_time_df = df.dropna(subset=[\"tair\"])\n",
    "\n",
    "    last_value = current_time_df[\"time_5M\"].iat[-1]\n",
    "    hour = last_value.hour\n",
    "    minute = last_value.minute\n",
    "    second = last_value.second\n",
    "\n",
    "    string_hour = str(hour)\n",
    "    string_minute = str(minute)\n",
    "    string_sec = str(second)\n",
    "\n",
    "    # time\n",
    "    time = string_hour + \":\" + string_minute + \":\" + string_sec\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # creating a new dataframe that is centered on the location in the dataframe\n",
    "    mesonet_single_datetime_df = df.loc[df[\"time_5M\"] == f\"{year}-{month}-{day} {time}\"]\n",
    "    return mesonet_single_datetime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return the most recent data avail on mesonet\n",
    "# this is my file path\n",
    "ny_df = pd.read_csv(\"/home/aevans/nwp_bias/src/landtype/notebooks/nysm_coords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return the most recent data avail on mesonet\n",
    "# this is my file path\n",
    "ny_mesonet_data_path = \"/home/aevans/nysm/archive/nysm/netcdf/proc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_df1 = current_time_mesonet_df(ny_mesonet_data_path)\n",
    "nysm_df = most_recent_time(nysm_df1, ny_mesonet_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_df[\"elev\"] = nysm_df[\"elev\"].to_list()\n",
    "ny_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.listdir(f\"/home/aevans/nwp_bias/src/landtype/elevation/data/NY/elev/nam\")\n",
    "sorted_direct = sorted(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to data\n",
    "path_ny = f\"/home/aevans/nwp_bias/src/landtype/elevation/data/CSVs_elevation_ny_gfs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_list_ny = ny_df[\"station\"].to_list()\n",
    "ny_df_lons = ny_df[\"longitude\"].to_list()\n",
    "ny_df_lats = ny_df[\"latitude\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "for i in range(1, 127):\n",
    "    df = pd.read_csv(\n",
    "        f\"/home/aevans/nwp_bias/src/landtype/elevation/data/CSVs_slope_ny_gfs/aspect_csv_{i}.csv\"\n",
    "    )\n",
    "    df.to_csv(\n",
    "        f\"/home/aevans/nwp_bias/src/landtype/elevation/data/NY/elev/gfs/{station_list_ny[x]}_elev.csv\"\n",
    "    )\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_df = stat_anal(sorted_direct, ny_df, station_list_ny, ny_df_lons, ny_df_lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_df.to_csv(\"/home/aevans/nwp_bias/src/correlation/data/elev_gfs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44818f36aeaf89db1a1d21a2bee6031a28b4e41595a65903b38b9b0c4417365f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
