{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "# instead of creating a package using setup.py or building from a docker/singularity file,\n",
    "# import the sister directory of src code to be called on in notebook.\n",
    "# This keeps the notebook free from code to only hold visualizations and is easier to test\n",
    "# It also helps keep the state of variables clean such that cells aren't run out of order with a mysterious state\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import calendar\n",
    "import time\n",
    "\n",
    "import boto\n",
    "import cartopy.crs as crs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from matplotlib import cm, colors\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "from src import plot_heatmaps\n",
    "from src import read_nwp_data\n",
    "from src import format_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canonical(lulc):\n",
    "    X = lulc.drop(columns=\"error\")\n",
    "    Y = lulc[[\"error\"]]\n",
    "    X_mc = (X - X.mean()) / (X.std())\n",
    "    Y_mc = (Y - Y.mean()) / (Y.std())\n",
    "    ca = CCA(n_components=1)\n",
    "    ca.fit(X_mc, Y_mc)\n",
    "    X_c, Y_c = ca.transform(X_mc, Y_mc)\n",
    "    cc_res = pd.DataFrame(\n",
    "        {\n",
    "            \"CCX_1\": X_c[:, 0],\n",
    "            \"CCY_1\": Y_c[:, 0],\n",
    "            \"19\": lulc[\"19\"].tolist(),\n",
    "            \"23\": lulc[\"23\"].tolist(),\n",
    "            \"26\": lulc[\"26\"].tolist(),\n",
    "            \"28\": lulc[\"28\"].tolist(),\n",
    "            \"27\": lulc[\"27\"].tolist(),\n",
    "            \"24\": lulc[\"24\"].tolist(),\n",
    "            \"25\": lulc[\"25\"].tolist(),\n",
    "            \"22\": lulc[\"22\"].tolist(),\n",
    "            \"32\": lulc[\"32\"].tolist(),\n",
    "        }\n",
    "    )\n",
    "    corr = np.corrcoef(X_c[:, 0], Y_c[:, 0])[0, 1]\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(months_df, lulc):\n",
    "    corr_ls = []\n",
    "    for i in np.arange(1, 13):\n",
    "        df = months_df[months_df[\"time\"] == i]\n",
    "        months = df[\"t2m_error\"].to_list()\n",
    "        lulc[\"error\"] = months\n",
    "        corr = canonical(lulc)\n",
    "        corr_ls.append(corr)\n",
    "    return corr_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = \"12\"\n",
    "\n",
    "(\n",
    "    gfs_fcast_and_error_df,\n",
    "    nam_fcast_and_error_df,\n",
    "    hrrr_fcast_and_error_df,\n",
    ") = read_nwp_data.read_data(init)\n",
    "gfs_fcast_and_error_df = gfs_fcast_and_error_df.reset_index()\n",
    "nam_fcast_and_error_df = nam_fcast_and_error_df.reset_index()\n",
    "hrrr_fcast_and_error_df = hrrr_fcast_and_error_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lulc = pd.read_csv(\"/home/aevans/nwp_bias/src/correlation/data/aspect_hrrr.csv\")\n",
    "lulc = lulc.drop(columns=[\"site\", \"station\"])\n",
    "keys = lulc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HRRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_df = format_error_df.format_df(hrrr_fcast_and_error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_ls = main(months_df, lulc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmaps.plot_heatmap(corr_ls, \"HRRR\", \"Aspect/Slope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Obtain the rotation matrices\n",
    "# xrot = ca.x_rotations_\n",
    "# yrot = ca.y_rotations_\n",
    "\n",
    "# # Put them together in a numpy matrix\n",
    "# xyrot = np.vstack((xrot,yrot))\n",
    "\n",
    "# nvariables = xyrot.shape[0]\n",
    "\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# plt.xlim((-1,1))\n",
    "# plt.ylim((-1,1))\n",
    "\n",
    "# # Plot an arrow and a text label for each variable\n",
    "# for var_i in range(nvariables):\n",
    "#   x = xyrot[var_i,0]\n",
    "#   y = xyrot[var_i,1]\n",
    "\n",
    "#   plt.arrow(0,0,x,y)\n",
    "#   plt.text(x,y,data.columns[i], color='red' if i >= 6 else 'blue')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44818f36aeaf89db1a1d21a2bee6031a28b4e41595a65903b38b9b0c4417365f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
