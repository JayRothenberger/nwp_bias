{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks for Image Recognition\n",
    "## Advanced Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/aevans/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -cipy (/home/aevans/miniconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCollecting pypng\r\n",
      "  Downloading pypng-0.20220715.0-py3-none-any.whl (58 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution -cipy (/home/aevans/miniconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: pypng\r\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -cipy (/home/aevans/miniconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0mSuccessfully installed pypng-0.20220715.0\r\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -cipy (/home/aevans/miniconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -cipy (/home/aevans/miniconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pypng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:51:40.704604: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-30 17:51:40.836034: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-05-30 17:51:42.271604: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /.singularity.d/libs:/home/aevans/miniconda3/lib/:/home/aevans/miniconda3/lib/\n",
      "2023-05-30 17:51:42.271930: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /.singularity.d/libs:/home/aevans/miniconda3/lib/:/home/aevans/miniconda3/lib/\n",
      "2023-05-30 17:51:42.271959: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import fnmatch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import (\n",
    "    Convolution2D,\n",
    "    Dense,\n",
    "    MaxPooling2D,\n",
    "    GlobalMaxPooling2D,\n",
    "    Flatten,\n",
    "    BatchNormalization,\n",
    "    Dropout,\n",
    "    SpatialDropout2D,\n",
    ")\n",
    "\n",
    "# from tensorflow.keras.optimizers import RMSprop\n",
    "import random\n",
    "import re\n",
    "\n",
    "# From pypng\n",
    "import png\n",
    "\n",
    "# from sklearn.p\n",
    "import sklearn.metrics\n",
    "\n",
    "##################\n",
    "# Configure figure parameters\n",
    "\n",
    "FONTSIZE = 18\n",
    "FIGURE_SIZE = (10, 4)\n",
    "FIGURE_SIZE2 = (10, 10)\n",
    "\n",
    "plt.rcParams.update({\"font.size\": FONTSIZE})\n",
    "plt.rcParams[\"figure.figsize\"] = FIGURE_SIZE\n",
    "# Default tick label size\n",
    "plt.rcParams[\"xtick.labelsize\"] = FONTSIZE\n",
    "plt.rcParams[\"ytick.labelsize\"] = FONTSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'core50_128x128/s1/o21'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Load up a single image & view it\u001b[39;00m\n\u001b[1;32m      2\u001b[0m directory \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcore50_128x128/s1/o21\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m files \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(directory)\n\u001b[1;32m      5\u001b[0m r \u001b[39m=\u001b[39m png\u001b[39m.\u001b[39mReader(directory \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m files[\u001b[39m0\u001b[39m])\n\u001b[1;32m      6\u001b[0m it \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mread()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'core50_128x128/s1/o21'"
     ]
    }
   ],
   "source": [
    "# Load up a single image & view it\n",
    "directory = \"core50_128x128/s1/o21\"\n",
    "files = os.listdir(directory)\n",
    "\n",
    "r = png.Reader(directory + \"/\" + files[0])\n",
    "it = r.read()\n",
    "image_2d = np.vstack(map(np.uint8, it[2]))\n",
    "image_3d = np.reshape(image_2d, (128, 128, 3))\n",
    "\n",
    "plt.imshow(image_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def readPngFile(filename):\n",
    "    \"\"\"\n",
    "    Read a single PNG file\n",
    "\n",
    "    filename = fully qualified file name\n",
    "\n",
    "    Return: 3D numpy array (rows x cols x chans)\n",
    "\n",
    "    Note: all pixel values are floats in the range 0.0 .. 1.0\n",
    "\n",
    "    This implementation relies on the pypng package\n",
    "    \"\"\"\n",
    "    # print(\"reading:\", filename)\n",
    "    # Load in the image meta-data\n",
    "    r = png.Reader(filename)\n",
    "    it = r.read()\n",
    "\n",
    "    # Load in the image itself and convert to a 2D array\n",
    "    image_2d = np.vstack(map(np.uint8, it[2]))\n",
    "\n",
    "    # Reshape into rows x cols x chans\n",
    "    image_3d = np.reshape(image_2d, (it[0], it[1], it[3][\"planes\"])) / 255.0\n",
    "    return image_3d\n",
    "\n",
    "\n",
    "def read_images_from_directory(directory, file_regexp):\n",
    "    \"\"\"\n",
    "    Read a set of images from a directory.  All of the images must be the same size\n",
    "\n",
    "    directory = Directory to search\n",
    "\n",
    "    file_regexp = a regular expression to match the file names against\n",
    "\n",
    "    Return: 4D numpy array (images x rows x cols x chans)\n",
    "    \"\"\"\n",
    "\n",
    "    print(directory, file_regexp)\n",
    "    # Get all of the file names\n",
    "    files = sorted(os.listdir(directory))\n",
    "\n",
    "    # Construct a list of images from those that match the regexp\n",
    "    list_of_images = [\n",
    "        readPngFile(directory + \"/\" + f) for f in files if re.search(file_regexp, f)\n",
    "    ]\n",
    "\n",
    "    # Create a 3D numpy array\n",
    "    return np.array(list_of_images, dtype=np.float32)\n",
    "\n",
    "\n",
    "def read_image_set_from_directories(directory, spec):\n",
    "    \"\"\"\n",
    "    Read a set of images from a set of directories\n",
    "\n",
    "    directory  = base directory to read from\n",
    "\n",
    "    spec = n x 2 array of subdirs and file regexps\n",
    "\n",
    "    Return: 4D numpy array (images x rows x cols x chans)\n",
    "\n",
    "    \"\"\"\n",
    "    out = read_images_from_directory(directory + \"/\" + spec[0][0], spec[0][1])\n",
    "    for sp in spec[1:]:\n",
    "        out = np.append(\n",
    "            out, read_images_from_directory(directory + \"/\" + sp[0], sp[1]), axis=0\n",
    "        )\n",
    "    return out\n",
    "\n",
    "\n",
    "def load_multiple_image_sets_from_directories(\n",
    "    directory_base, directory_list, object_list, test_files\n",
    "):\n",
    "    \"\"\" \"\"\"\n",
    "    print(\"##################\")\n",
    "    # Create the list of object/image specs\n",
    "    inputs = [[obj, test_files] for obj in object_list]\n",
    "\n",
    "    # First directory\n",
    "    ret = read_image_set_from_directories(\n",
    "        directory_base + \"/\" + directory_list[0], inputs\n",
    "    )\n",
    "\n",
    "    # Loop over directories\n",
    "    for directory in directory_list[1:]:\n",
    "        ret = np.append(\n",
    "            ret,\n",
    "            read_image_set_from_directories(directory_base + \"/\" + directory, inputs),\n",
    "            axis=0,\n",
    "        )\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## File location\n",
    "directory_base = \"core50_128x128\"\n",
    "\n",
    "# Training set: define which files to load for each object\n",
    "# test_files = '.*[05].png'\n",
    "test_files = \".*[0].png\"\n",
    "\n",
    "### Positive cases\n",
    "# Define which objects to load\n",
    "# object_list = ['o25', 'o22', 'o23', 'o24']\n",
    "object_list = [\"o21\"]\n",
    "\n",
    "# Define which conditions to load\n",
    "# condition_list = ['s1', 's2', 's3', 's4', 's5', 's7', 's8', 's9', 's10', 's11']\n",
    "# condition_list = ['s1', 's2', 's3', 's4']\n",
    "condition_list = [\"s1\"]\n",
    "\n",
    "# Load all of the objects/condition\n",
    "ins_pos = load_multiple_image_sets_from_directories(\n",
    "    directory_base, condition_list, object_list, test_files\n",
    ")\n",
    "\n",
    "### Negative cases\n",
    "# Define which objects to load\n",
    "# object_list2 = ['o45', 'o42', 'o43', 'o44']\n",
    "object_list2 = [\"o41\"]\n",
    "ins_neg = load_multiple_image_sets_from_directories(\n",
    "    directory_base, condition_list, object_list2, test_files\n",
    ")\n",
    "\n",
    "### Combine positives and negatives into a common data set\n",
    "outs_pos = np.append(\n",
    "    np.ones((ins_pos.shape[0], 1)), np.zeros((ins_pos.shape[0], 1)), axis=1\n",
    ")\n",
    "outs_neg = np.append(\n",
    "    np.zeros((ins_pos.shape[0], 1)), np.ones((ins_pos.shape[0], 1)), axis=1\n",
    ")\n",
    "\n",
    "ins = np.append(ins_pos, ins_neg, axis=0)\n",
    "outs = np.append(outs_pos, outs_neg, axis=0)\n",
    "\n",
    "########################################################################\n",
    "# Validation set\n",
    "# Define which files to load for each object\n",
    "test_files = \".*[5].png\"\n",
    "\n",
    "### Positives\n",
    "# Define which objects to load\n",
    "object_list = [\"o21\"]\n",
    "# object_list = ['o21']\n",
    "\n",
    "# Load the positives\n",
    "ins_pos_validation = load_multiple_image_sets_from_directories(\n",
    "    directory_base, condition_list, object_list, test_files\n",
    ")\n",
    "\n",
    "### Negatives\n",
    "# Define objects\n",
    "object_list2 = [\"o41\"]\n",
    "# object_list2 = ['o41']\n",
    "\n",
    "# Load the negative cases\n",
    "ins_neg_validation = load_multiple_image_sets_from_directories(\n",
    "    directory_base, condition_list, object_list2, test_files\n",
    ")\n",
    "\n",
    "### Combine positives and negatives\n",
    "outs_pos_validation = np.append(\n",
    "    np.ones((ins_pos_validation.shape[0], 1)),\n",
    "    np.zeros((ins_pos_validation.shape[0], 1)),\n",
    "    axis=1,\n",
    ")\n",
    "outs_neg_validation = np.append(\n",
    "    np.zeros((ins_pos_validation.shape[0], 1)),\n",
    "    np.ones((ins_pos_validation.shape[0], 1)),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "ins_validation = np.append(ins_pos_validation, ins_neg_validation, axis=0)\n",
    "outs_validation = np.append(outs_pos_validation, outs_neg_validation, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ins_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outs_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_classifier_network(\n",
    "    image_size,\n",
    "    nchannels,\n",
    "    n_classes,\n",
    "    learning_rate=0.0001,\n",
    "    lambda_l2=0.0001,\n",
    "    p_dropout=None,\n",
    "    p_spatial_dropout=None,\n",
    "    n_filters=[10],\n",
    "    kernel_size=[3],\n",
    "    pooling=[1],\n",
    "    n_hidden=[5],\n",
    "):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(image_size[0], image_size[1], nchannels)))\n",
    "\n",
    "    # convolutional layers\n",
    "    for i, (n, s, p) in enumerate(zip(n_filters, kernel_size, pooling)):\n",
    "        model.add(\n",
    "            Convolution2D(\n",
    "                filters=n,\n",
    "                kernel_size=s,\n",
    "                padding=\"same\",\n",
    "                use_bias=True,\n",
    "                name=\"C%d\" % (i),\n",
    "                activation=\"elu\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if p_spatial_dropout is not None:\n",
    "            model.add(SpatialDropout2D(p_spatial_dropout))\n",
    "\n",
    "        if p > 1:\n",
    "            model.add(MaxPooling2D(pool_size=p, strides=p, name=\"MP%d\" % (i)))\n",
    "\n",
    "    # Flatten\n",
    "    model.add(GlobalMaxPooling2D())\n",
    "\n",
    "    # Dense layers\n",
    "    for i, n in enumerate(n_hidden):\n",
    "        model.add(Dense(units=n, activation=\"elu\", use_bias=\"True\", name=\"D%d\" % i))\n",
    "\n",
    "        if p_dropout is not None:\n",
    "            model.add(Dropout(p_dropout))\n",
    "\n",
    "    # Output\n",
    "    model.add(\n",
    "        Dense(units=n_classes, activation=\"softmax\", use_bias=\"True\", name=\"output\")\n",
    "    )\n",
    "\n",
    "    # Optimizer\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate, amsgrad=False)\n",
    "\n",
    "    # Bind the model to the optimizer\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"categorical_accuracy\"]\n",
    "    )\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = create_classifier_network(\n",
    "    (ins.shape[1], ins.shape[2]),\n",
    "    ins.shape[3],\n",
    "    2,\n",
    "    learning_rate=0.0001,\n",
    "    p_spatial_dropout=0.1,\n",
    "    # p_dropout=0.5,\n",
    "    n_filters=[10, 20, 20, 40, 40, 80],\n",
    "    kernel_size=[3, 3, 5, 5, 5, 5],\n",
    "    pooling=[0, 2, 0, 2, 0, 2],\n",
    "    n_hidden=[40, 20, 10, 5],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
    "    patience=10, restore_best_weights=True, min_delta=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x=ins,\n",
    "    y=outs,\n",
    "    epochs=30,\n",
    "    verbose=1,\n",
    "    validation_data=(ins_validation, outs_validation),\n",
    "    callbacks=[early_stopping_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"], label=\"Training\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history[\"categorical_accuracy\"], label=\"Training\")\n",
    "plt.plot(history.history[\"val_categorical_accuracy\"], label=\"Validation\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ins_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.argmax(model.predict(ins_validation), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "outs_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_roc(model, ins, outs, ins_validation, outs_validation):\n",
    "    \"\"\"\n",
    "    Produce a ROC plot given a model, a set of inputs and the true outputs\n",
    "\n",
    "    Assume that model produces N-class output; we will only look at the class 0 scores\n",
    "    \"\"\"\n",
    "    # Compute probabilistic predictions given images\n",
    "    pred = model.predict(ins)\n",
    "    # Compute false positive rate & true positive rate + AUC\n",
    "    fpr, tpr, thresholds = sklearn.metrics.roc_curve(outs[:, 0], pred[:, 0])\n",
    "    auc = sklearn.metrics.auc(fpr, tpr)\n",
    "\n",
    "    # Compute probabilistic predictions given images\n",
    "    pred_val = model.predict(ins_validation)\n",
    "    # Compute false positive rate & true positive rate + AUC\n",
    "    fpr_val, tpr_val, thresholds_val = sklearn.metrics.roc_curve(\n",
    "        outs_validation[:, 0], pred_val[:, 0]\n",
    "    )\n",
    "    auc_val = sklearn.metrics.auc(fpr_val, tpr_val)\n",
    "\n",
    "    # Generate the plot\n",
    "    plt.figure(1)\n",
    "    plt.axis(\"equal\")\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.plot(fpr, tpr, \"b\", label=\"Train AUC = {:.3f}\".format(auc))\n",
    "    plt.plot(fpr_val, tpr_val, \"r\", label=\"Validation AUC = {:.3f}\".format(auc_val))\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(\"FPR\", fontsize=FONTSIZE)\n",
    "    plt.ylabel(\"TPR\", fontsize=FONTSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_roc(model, ins, outs, ins_validation, outs_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Model Internals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def intermediate_model_state(model, ins, layer_list):\n",
    "    \"\"\"\n",
    "    Return layer activations for intermediate layers in a model for a set of examples\n",
    "\n",
    "    :param model: Model in question\n",
    "    :param ins: Input tensor (examples, rows, cols, channels)\n",
    "    :param layer_list: List of layer names to produce activations for\n",
    "    :returns: a list of numpy arrays\n",
    "    \"\"\"\n",
    "    # Translate layer names into corresponding output tensors\n",
    "    layer_outputs = [l.output for l in model.layers if l.name in layer_list]\n",
    "\n",
    "    # Construct a new Keras model that outputs these tensors\n",
    "    # The internal structure of the model itself is referenced through the input and output tensor lists\n",
    "    new_model = keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "    # Evaluate the new model\n",
    "    activations = new_model.predict(ins)\n",
    "\n",
    "    # Return a list of activation numpy arrays\n",
    "    return activations\n",
    "\n",
    "\n",
    "def visualize_state(activations, width=1, example=0, cmap=\"plasma\"):\n",
    "    \"\"\"\n",
    "    Produce graphical representation of a set of image channels\n",
    "\n",
    "    :param activations: numpy array (example, rows, cols, channels)\n",
    "    :param width: Number of images displayed horizontally\n",
    "    :param example: Index of example to display\n",
    "    :param cmap: Color map to use for plotting\n",
    "    \"\"\"\n",
    "    # Size of the individual images\n",
    "    nrows = activations.shape[1]\n",
    "    ncols = activations.shape[2]\n",
    "    # Number of channels\n",
    "    nfilters = activations.shape[3]\n",
    "\n",
    "    # Tile all of the sub-images\n",
    "    grid = np.zeros((int((nfilters - 1) / width + 1) * nrows, ncols * width))\n",
    "\n",
    "    # Loop over image\n",
    "    for i in range(nfilters):\n",
    "        # Compute r,c of tile to place the ith image into\n",
    "        r = int(i / width)\n",
    "        c = i % width\n",
    "        grid[nrows * r : nrows * (r + 1), ncols * c : ncols * (c + 1)] = activations[\n",
    "            example, :, :, i\n",
    "        ]\n",
    "\n",
    "    # Plot\n",
    "    plt.matshow(grid, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute activations for 2 layers over a set of examples\n",
    "layer_list = [\"C5\"]\n",
    "activations = intermediate_model_state(model, ins_validation, layer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot convolutional layers 1 and 2\n",
    "example = 20\n",
    "plt.imshow(ins_validation[example, :, :, :])\n",
    "visualize_state(activations, width=10, example=example)\n",
    "# visualize_state(activations[0], width=10, example=example)\n",
    "# visualize_state(activations[1], width=20, example=example)\n",
    "# visualize_state(activations[2], width=20, example=example)\n",
    "# visualize_state(activations[3], width=30, example=example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot convolutional layers 1 and 2\n",
    "example = 40\n",
    "plt.imshow(ins_validation[example, :, :, :])\n",
    "visualize_state(activations, width=10, example=example)\n",
    "# visualize_state(activations[0], width=10, example=example)\n",
    "# visualize_state(activations[1], width=20, example=example)\n",
    "# visualize_state(activations[2], width=20, example=example)\n",
    "# visualize_state(activations[3], width=30, example=example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "44818f36aeaf89db1a1d21a2bee6031a28b4e41595a65903b38b9b0c4417365f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
