{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "# instead of creating a package using setup.py or building from a docker/singularity file,\n",
    "# import the sister directory of src code to be called on in notebook.\n",
    "# This keeps the notebook free from code to only hold visualizations and is easier to test\n",
    "# It also helps keep the state of variables clean such that cells aren't run out of order with a mysterious state\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.pytorch import log_model\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(init):\n",
    "    \"\"\"\n",
    "    Reads and concatenates parquet files containing forecast and error data for GFS, NAM, and HRRR weather models\n",
    "    for the years 2018 to 2021, with random forecasts that have a forecast hour of 0 removed.\n",
    "\n",
    "    Args:\n",
    "        init (str): A string representing the initial time of the forecast (in UTC).\n",
    "\n",
    "    Returns:\n",
    "        tuple of pandas.DataFrame: A tuple containing three dataframes, one for each weather model, with random\n",
    "        forecasts that have a forecast hour of 0 removed.\n",
    "    \"\"\"\n",
    "    years = [\"2018\", \"2019\", \"2020\", \"2021\"]\n",
    "    savedir = \"/home/aevans/ai2es/processed_data/frcst_err/\"\n",
    "\n",
    "    # create empty lists to hold dataframes for each model\n",
    "    nam_fcast_and_error = []\n",
    "    gfs_fcast_and_error = []\n",
    "    hrrr_fcast_and_error = []\n",
    "\n",
    "    # loop over years and read in parquet files for each model\n",
    "    for year in years:\n",
    "        nam_fcast_and_error.append(\n",
    "            pd.read_parquet(\n",
    "                f\"{savedir}nam_fcast_and_error_df_{init}z_{year}_mask_water_ny.parquet\"\n",
    "            )\n",
    "        )\n",
    "        gfs_fcast_and_error.append(\n",
    "            pd.read_parquet(\n",
    "                f\"{savedir}gfs_fcast_and_error_df_{init}z_{year}_mask_water_ny.parquet\"\n",
    "            )\n",
    "        )\n",
    "        hrrr_fcast_and_error.append(\n",
    "            pd.read_parquet(\n",
    "                f\"{savedir}hrrr_fcast_and_error_df_{init}z_{year}_mask_water_ny.parquet\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # concatenate dataframes for each model\n",
    "    nam_fcast_and_error_df = pd.concat(nam_fcast_and_error)\n",
    "    gfs_fcast_and_error_df = pd.concat(gfs_fcast_and_error)\n",
    "    hrrr_fcast_and_error_df = pd.concat(hrrr_fcast_and_error)\n",
    "\n",
    "    # remove random forecasts that have forecast hours 0 for each model\n",
    "    gfs_fcast_and_error_df = gfs_fcast_and_error_df[\n",
    "        gfs_fcast_and_error_df[\"lead_time_ONLY_HOURS\"] != 0.0\n",
    "    ]\n",
    "    nam_fcast_and_error_df = nam_fcast_and_error_df[\n",
    "        nam_fcast_and_error_df[\"lead_time_ONLY_HOURS\"] != 0.0\n",
    "    ]\n",
    "    hrrr_fcast_and_error_df = hrrr_fcast_and_error_df[\n",
    "        hrrr_fcast_and_error_df[\"lead_time_ONLY_HOURS\"] != 0.0\n",
    "    ]\n",
    "\n",
    "    # return dataframes for each model\n",
    "    return gfs_fcast_and_error_df, nam_fcast_and_error_df, hrrr_fcast_and_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfs_fcast_and_error_df, nam_fcast_and_error_df, hrrr_fcast_and_error_df = read_data(\n",
    "    \"12\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nam_fcast_and_error_df = nam_fcast_and_error_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_df = pd.read_csv(\"/home/aevans/nwp_bias/src/landtype/data/nysm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_df = nysm_df[nysm_df[\"climate_division\"] == 1]\n",
    "hudson_ls = nysm_df[\"stid\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nam_fcast_and_error_df = nam_fcast_and_error_df[\n",
    "    nam_fcast_and_error_df[\"station\"].isin(hudson_ls)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = nam_fcast_and_error_df[\"station\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = nam_fcast_and_error_df[nam_fcast_and_error_df[\"station\"] == stations[0]]\n",
    "master_df = master_df.drop(\n",
    "    columns=[\n",
    "        \"station\",\n",
    "        \"time\",\n",
    "        \"t2m_error\",\n",
    "        \"d2m_error\",\n",
    "        \"u_total_error\",\n",
    "        \"u_dir_error\",\n",
    "        \"new_tp_error\",\n",
    "        \"prmsl_error\",\n",
    "        \"lead_time_DAY\",\n",
    "        \"lead_time_HOUR\",\n",
    "        \"lead_time_ONLY_HOURS\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for station in stations:\n",
    "    df = nam_fcast_and_error_df[nam_fcast_and_error_df[\"station\"] == station]\n",
    "    df = df.drop(\n",
    "        columns=[\n",
    "            \"station\",\n",
    "            \"time\",\n",
    "            \"t2m_error\",\n",
    "            \"d2m_error\",\n",
    "            \"u_total_error\",\n",
    "            \"u_dir_error\",\n",
    "            \"new_tp_error\",\n",
    "            \"prmsl_error\",\n",
    "            \"lead_time_DAY\",\n",
    "            \"lead_time_HOUR\",\n",
    "            \"lead_time_ONLY_HOURS\",\n",
    "        ]\n",
    "    )\n",
    "    master_df = master_df.merge(df, on=\"valid_time\", suffixes=(None, f\"_{station}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['station', 'valid_time', 'time', 't2m_NAM', 'd2m_NAM', 'u_total_NAM',\n",
       "       'u_dir_NAM', 'latitude', 'longitude', 'new_tp_NAM', 'prmsl_NAM', 'orog',\n",
       "       't2m_error', 'd2m_error', 'u_total_error', 'u_dir_error',\n",
       "       'new_tp_error', 'prmsl_error', 't2m_nysm', 'd2m_nysm', 'u_total_nysm',\n",
       "       'u_dir_nysm', 'new_tp_nysm', 'prmsl_nysm', 'lead_time_DAY',\n",
       "       'lead_time_HOUR', 'lead_time_ONLY_HOURS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nam_fcast_and_error_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44818f36aeaf89db1a1d21a2bee6031a28b4e41595a65903b38b9b0c4417365f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
